{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import difflib\n",
    "import os\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# вывод разницы версий файла\n",
    "def print_diff(prev_file_lines, file_path):\n",
    "    print(f\"\\n{file_path}:\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        diff = difflib.unified_diff(prev_file_lines, file.readlines())\n",
    "\n",
    "    for line in diff:\n",
    "        print(line, end=\"\" if line[-1] == \"\\n\" else \"\\n\")\n",
    "\n",
    "def rewrite_in_file(file_path, insert_place, new_text, is_logged=True):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    prev_lines = lines[:]\n",
    "\n",
    "    # Место для вставки\n",
    "    for i in range(len(lines)):\n",
    "        if insert_place in lines[i]:\n",
    "            brackets_num = lines[i].count(\"{\") - lines[i].count(\"}\")\n",
    "            lines.pop(i)\n",
    "            while brackets_num > 0:\n",
    "                brackets_num += lines[i].count(\"{\") - lines[i].count(\"}\")\n",
    "                lines.pop(i)\n",
    "            lines.insert(i, new_text)\n",
    "            break\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    if is_logged:\n",
    "        print_diff(prev_lines, file_path)\n",
    "\n",
    "def write_in_file(file_path, insert_place, new_text, is_logged=True):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "    prev_lines = lines[:]\n",
    "\n",
    "    # Место для вставки\n",
    "    for i in range(len(lines)):\n",
    "        if insert_place in lines[i]:\n",
    "            lines.insert(i, new_text)\n",
    "            break\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    if is_logged:\n",
    "        print_diff(prev_lines, file_path)\n",
    "\n",
    "# мапа как в интерпретаторе (список функций по имени)\n",
    "names_to_funcs = {}\n",
    "for f in data[\"functions\"]:\n",
    "    if not names_to_funcs.get(f[\"name\"]):\n",
    "        names_to_funcs[f[\"name\"]] = []\n",
    "    names_to_funcs[f[\"name\"]].append(f)\n",
    "    f[\"id\"] = len(names_to_funcs[f[\"name\"]])\n",
    "# имена шаблонов\n",
    "for f in data[\"functions\"]:\n",
    "    f[\"template_name\"] = f[\"name\"]\n",
    "    if len(names_to_funcs[f[\"name\"]]) > 1:\n",
    "        f[\"template_name\"] += str(f[\"id\"])\n",
    "for f in data['functions']:\n",
    "    f.setdefault('need_template', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация cpp кода вектора функций интерпретатора\n",
    "def generate_funcs_vector():\n",
    "    funcs_vector = \"inline static const std::vector<Function> functions = {\\n\"\n",
    "    for func in data[\"functions\"]:\n",
    "        input = [f\"ObjectType::{type}\" for type in func[\"arguments\"]]\n",
    "        funcs_vector += f'\\t{{\"{func[\"name\"]}\", {{{\", \".join(input)}}}, ObjectType::{func[\"return_type\"]}}},\\n'\n",
    "    funcs_vector += \"};\\n\"\n",
    "    return funcs_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exist_func_with_same_name(name):\n",
    "    count = sum(1 for func in data[\"functions\"] if func[\"name\"] == name)\n",
    "    return count > 1\n",
    "\n",
    "def is_child(type1, type2):\n",
    "    if \"children\" not in data[\"types\"][type2]:\n",
    "        return False\n",
    "    return type1 in data[\"types\"][type2][\"children\"]\n",
    "\n",
    "def same_input_output_types(func):\n",
    "    type1 = func[\"arguments\"][0]\n",
    "    type2 = func[\"return_type\"]\n",
    "    return type1 == type2 or is_child(type1, type2) or is_child(type2, type1)\n",
    "\n",
    "def get_func_mini_head(func):\n",
    "    handler_str = f'if (function.name == \"{func[\"name\"]}\"'\n",
    "    if exist_func_with_same_name(func[\"name\"]):\n",
    "        handler_str += f' && function.input[0] == ObjectType::{func[\"arguments\"][0]}'\n",
    "    handler_str += \") {\\n\"\n",
    "    return handler_str\n",
    "\n",
    "\n",
    "# генерация cpp кода обработчика функции интерпретатора\n",
    "def generate_func_handler(func):\n",
    "    arg_types = func[\"arguments\"]\n",
    "    handler_str = \"\\t\" + get_func_mini_head(func)\n",
    "    handler_str += \"\\t\\treturn \"\n",
    "    handler_str += f'Object{func[\"return_type\"]}('\n",
    "    if len(func[\"arguments\"]) < 1:\n",
    "        print(f\"error: func {func['name']} has 0 args\")\n",
    "    else:\n",
    "        handler_str += (\n",
    "            f'get<Object{arg_types[0]}>(arguments[0]).value.{func[\"prog_name\"]}('\n",
    "        )\n",
    "        for j in range(1, len(arg_types)):\n",
    "            handler_str += f\"get<Object{arg_types[j]}>(arguments[{j}]).value, \"\n",
    "        handler_str += \"&log_template)\"\n",
    "    handler_str += \");\\n\\t}\\n\"\n",
    "    return handler_str\n",
    "\n",
    "\n",
    "def add_to_interpreter_apply_function():\n",
    "    interpreter_path = data[\"chipollino_path\"] + \"/libs/Interpreter/src/Interpreter.cpp\"\n",
    "    with open(interpreter_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prev_lines = file.readlines()\n",
    "\n",
    "    with open(interpreter_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        file_content = file.read()\n",
    "        for func in data[\"functions\"]:\n",
    "            if f'if (function.name == \"{func[\"name\"]}\"' not in file_content: # нужен рабский труд чтобы исп-ть get_func_mini_head(func)\n",
    "                if same_input_output_types(func):\n",
    "                    insert_place = \"# place for another same types funcs\"\n",
    "                else:\n",
    "                    insert_place = \"# place for another diff types funcs\"\n",
    "                write_in_file(\n",
    "                    file_path=interpreter_path,\n",
    "                    insert_place=insert_place,\n",
    "                    new_text=generate_func_handler(func),\n",
    "                    is_logged=False\n",
    "                )\n",
    "    print_diff(prev_lines, interpreter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(file_path, hint, end_mark=\"}\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        file_content = file.read()\n",
    "    insert_index = file_content.find(hint)\n",
    "    if insert_index == -1:\n",
    "        print(\"not found \" + hint)\n",
    "        return\n",
    "    brace_index = file_content.find(end_mark, insert_index)\n",
    "\n",
    "    return (\n",
    "        file_content[:insert_index],\n",
    "        file_content[insert_index:brace_index],\n",
    "        file_content[brace_index:],\n",
    "    )\n",
    "\n",
    "def add_to_ObjectType(file_path):\n",
    "    insert_place = \"enum class ObjectType {\"\n",
    "    file_begin, placeholder, file_end = get_content(file_path, insert_place)\n",
    "    for type in data[\"types\"]:\n",
    "        if type not in placeholder:\n",
    "            placeholder += f\"\\t{type},\\n\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def add_to_structs(file_path):\n",
    "    insert_place = \"// Сами структуры\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\"\\n\\n\"\n",
    "    )\n",
    "    for type, info in data[\"types\"].items():\n",
    "        if \"Object\" + type not in placeholder and info != None:\n",
    "            placeholder += f\"\\nstruct Object{type};\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def add_to_GeneralObject(file_path):\n",
    "    insert_place = \"using GeneralObject =\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\">\"\n",
    "    )\n",
    "    for type, info in data[\"types\"].items():\n",
    "        if \"Object\" + type not in placeholder and info != None:\n",
    "            placeholder += f\", Object{type}\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "\"\"\"\n",
    "def generate_object_definitions():\n",
    "    res_str = \"\"\n",
    "    for name, info in data[\"types\"].items():\n",
    "        if info == None:\n",
    "            continue\n",
    "        res_str += f'OBJECT_DEFINITION({name}, {info[\"class\"]})\\n'\n",
    "    return res_str\"\"\"\n",
    "\n",
    "def add_to_object_definitions(file_path):\n",
    "    insert_place = \"// Определение структур объектов\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\"\\n\\n\"\n",
    "    )\n",
    "    for type, info in data[\"types\"].items():\n",
    "        if f\"({type},\" not in placeholder and info != None:\n",
    "            placeholder += f'\\nOBJECT_DEFINITION({type}, {info[\"class\"]})'\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def generate_map_types_to_str():\n",
    "    map_str = \"inline static const std::unordered_map<ObjectType, std::string> types_to_string = {\\n\"\n",
    "    for type in data[\"types\"]:\n",
    "        map_str += f'\\t{{ObjectType::{type}, \"{type}\"}},\\n'\n",
    "    map_str += \"};\\n\"\n",
    "    return map_str\n",
    "\n",
    "def add_to_typization():\n",
    "    typization_path = data[\"chipollino_path\"] + \"/libs/FuncLib/include/FuncLib/Typization.h\"\n",
    "\n",
    "    with open(typization_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prev_lines = file.readlines()\n",
    "\n",
    "    add_to_ObjectType(typization_path)\n",
    "    add_to_structs(typization_path)\n",
    "    add_to_GeneralObject(typization_path)\n",
    "    add_to_object_definitions(typization_path)\n",
    "    rewrite_in_file(\n",
    "        file_path=typization_path,\n",
    "        insert_place=\"unordered_map<ObjectType, std::string> types_to_string\",\n",
    "        new_text=generate_map_types_to_str(),\n",
    "        is_logged = False\n",
    "    )\n",
    "\n",
    "    print_diff(prev_lines, typization_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_tex_types(file_path):\n",
    "    insert_place = \"% типы интерпретатора\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\"\\def\\TypeIs\"\n",
    "    )\n",
    "    for type, info in data[\"types\"].items():\n",
    "        if \"\\\\def\\\\\" + type not in placeholder and info != None:\n",
    "            placeholder += f\"\\\\def\\\\{type}TYPE{{\\\\mathtt{{{type}}}}}\\n\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def add_to_tex_func_names(file_path):\n",
    "    insert_place = \"% названия операций\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\"\\n% типы интерпретатора\"\n",
    "    )\n",
    "    for f in data[\"functions\"]:\n",
    "        if \"\\\\def\\\\\" + f[\"name\"] not in placeholder and f[\"need_template\"]:\n",
    "            placeholder += f\"\\\\def\\\\{f['name']}{{\\\\mathtt{{{f['name']}}}}}\\n\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def add_to_tex_head():\n",
    "    tex_head_path = data[\"chipollino_path\"] + \"/resources/template/head.tex\"\n",
    "    with open(tex_head_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prev_lines = file.readlines()\n",
    "\n",
    "    add_to_tex_func_names(tex_head_path)\n",
    "    add_to_tex_types(tex_head_path)\n",
    "    print_diff(prev_lines, tex_head_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_readme_types(file_path):\n",
    "    insert_place = \"Интерпретатор поддерживает следующие типы:\"\n",
    "    file_begin, placeholder, file_end = get_content(file_path, insert_place, end_mark=\"\\n### Синтаксические конструкции\")\n",
    "    for type, info in data[\"types\"].items():\n",
    "        if type not in placeholder and info != None:\n",
    "            placeholder += f\"* {type}\\n\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "def add_readme_funcs(file_path):\n",
    "    def create_func_readme(f):\n",
    "        if len(f[\"arguments\"]) == 1:\n",
    "            return f\"- `{f['name']}: {f['arguments'][0]} -> {f['return_type']}`\"\n",
    "        return f\"- `{f['name']}: ({', '.join(f['arguments'])}) -> {f['return_type']}`\"\n",
    "    insert_place = \"Функции преобразователя\"\n",
    "    file_begin, placeholder, file_end = get_content(\n",
    "        file_path, insert_place, end_mark=\"\\n**Метод Test**\"\n",
    "    )\n",
    "    for f in data[\"functions\"]:\n",
    "        if create_func_readme(f) not in placeholder:\n",
    "            placeholder += create_func_readme(f) + \"\\n\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(file_begin + placeholder + file_end)\n",
    "\n",
    "    \n",
    "def add_to_readme():\n",
    "    readme_path = data[\"chipollino_path\"] + \"/README.md\"\n",
    "    with open(readme_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        prev_lines = file.readlines()\n",
    "    add_readme_types(readme_path)\n",
    "    add_readme_funcs(readme_path)\n",
    "    print_diff(prev_lines, readme_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "# Создаем экземпляр класса MorphAnalyzer\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def generate_template(f):\n",
    "    file_content = f\"\\\\section{{{f['name']}}}\\n\"\n",
    "    file_content += f\"\\\\begin{{frame}}{{$\\\\{f['name']}\\\\TypeIs\"\n",
    "    # хз что делать если аргументов > 2\n",
    "    if len(f[\"arguments\"]) == 1:\n",
    "        file_content += f\"\\\\{f['arguments'][0]}TYPE\"\n",
    "    else:\n",
    "        file_content += f\"\\\\pair{{\\\\{f['arguments'][0]}TYPE}}{{\\\\{f['arguments'][1]}TYPE}}\"\n",
    "    file_content += f\"\\\\to\\\\{f['return_type']}TYPE$}}\\n\"\n",
    "    # генерация аргументов:\n",
    "    if len(f[\"arguments\"]) == 1:\n",
    "        type = data[\"types\"][f[\"arguments\"][0]]\n",
    "        file_content += f\"\\t{type['ru_str'].capitalize()}\"\n",
    "        if type[\"class\"] == data[\"types\"][f[\"return_type\"]][\"class\"]:\n",
    "            file_content += \" до преобразования:\\n\"\n",
    "            file_content += f\"\\t%template_old{f['arguments'][0].lower()}\\n\\n\"\n",
    "        else:\n",
    "            file_content += \":\\n\"\n",
    "            file_content += f\"\\t%template_{f['arguments'][0].lower()}\\n\\n\"\n",
    "    elif len(f[\"arguments\"]) == 2 and data[\"types\"][f[\"arguments\"][0]][\"class\"] == data[\"types\"][f[\"arguments\"][1]][\"class\"]:\n",
    "        type1 = data[\"types\"][f[\"arguments\"][0]]\n",
    "        # Склоняем прилагательное по роду\n",
    "        arg1_ru_str = morph.parse(\"первый\")[0].inflect({morph.parse(type1[\"ru_str\"])[0].tag.gender}).word + \" \" + type1[\"ru_str\"]\n",
    "        file_content += f\"\\t{arg1_ru_str.capitalize()}:\\n\"\n",
    "        file_content += f\"\\t%template_{f['arguments'][0].lower()}1\\n\\n\"\n",
    "        type2 = data[\"types\"][f[\"arguments\"][1]]\n",
    "        arg2_ru_str = morph.parse(\"вторая\")[0].inflect({morph.parse(type2[\"ru_str\"])[0].tag.gender}).word + \" \" + type2[\"ru_str\"]\n",
    "        file_content += f\"\\t{arg2_ru_str.capitalize()}:\\n\"\n",
    "        file_content += f\"\\t%template_{f['arguments'][1].lower()}2\\n\\n\"\n",
    "    else:\n",
    "        for i in range(len(f[\"arguments\"])):\n",
    "            file_content += f\"\\t%template_{f['arguments'][i].lower()}{i+1}\\n\\n\"\n",
    "\n",
    "    # генерация результата        \n",
    "    if len(f[\"arguments\"]) == 1 and data[\"types\"][f[\"arguments\"][0]][\"class\"] == data[\"types\"][f[\"return_type\"]][\"class\"]:\n",
    "        file_content += f\"\\t{data['types'][f['return_type']]['ru_str'].capitalize()} после преобразования:\\n\"\n",
    "    else:\n",
    "        file_content += f\"\\tРезультат:\\n\"\n",
    "    file_content += \"\\t%template_result\\n\\n\"\n",
    "    file_content += \"\\\\end{frame}\"\n",
    "    return file_content\n",
    "\n",
    "def generate_templates():\n",
    "    for f in data[\"functions\"]:\n",
    "        file_path = data[\"chipollino_path\"] + f'/resources/template/{f[\"template_name\"]}.tex'\n",
    "        if not os.path.exists(file_path) and f[\"need_template\"]:\n",
    "            # создание файла\n",
    "            with open(file_path, \"w\") as file:\n",
    "                pass\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                prev_lines = file.readlines()\n",
    "                \n",
    "            file_content = generate_template(f)\n",
    "\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(file_content)\n",
    "            print_diff(prev_lines, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./Chipollino/libs/FuncLib/include/FuncLib/Functions.h:\n",
      "--- \n",
      "+++ \n",
      "@@ -45,7 +45,6 @@\n",
      " \t{\"Intersect\", {ObjectType::NFA, ObjectType::NFA}, ObjectType::NFA},\n",
      " \t{\"Union\", {ObjectType::NFA, ObjectType::NFA}, ObjectType::NFA},\n",
      " \t{\"Difference\", {ObjectType::NFA, ObjectType::NFA}, ObjectType::NFA},\n",
      "-\t// Многосортные функции\n",
      " \t{\"PumpLength\", {ObjectType::Regex}, ObjectType::Int},\n",
      " \t{\"ClassLength\", {ObjectType::NFA}, ObjectType::Int},\n",
      " \t{\"Normalize\", {ObjectType::Regex, ObjectType::Array}, ObjectType::Regex},\n",
      "@@ -56,9 +55,7 @@\n",
      " \t{\"GlaisterShallit\", {ObjectType::NFA}, ObjectType::Int},\n",
      " \t{\"PrefixGrammar\", {ObjectType::NFA}, ObjectType::PrefixGrammar},\n",
      " \t{\"PGtoNFA\", {ObjectType::PrefixGrammar}, ObjectType::NFA},\n",
      "-\t// Предикаты\n",
      " \t{\"Bisimilar\", {ObjectType::NFA, ObjectType::NFA}, ObjectType::Boolean},\n",
      "-\t// для dfa - bool, для nfa - std::optional<bool>\n",
      " \t{\"Minimal\", {ObjectType::NFA}, ObjectType::OptionalBool},\n",
      " \t{\"Deterministic\", {ObjectType::NFA}, ObjectType::Boolean},\n",
      " \t{\"Subset\", {ObjectType::Regex, ObjectType::Regex}, ObjectType::Boolean},\n",
      "\n",
      "./Chipollino/libs/Interpreter/src/Interpreter.cpp:\n",
      "\n",
      "./Chipollino/libs/FuncLib/include/FuncLib/Typization.h:\n",
      "\n",
      "./Chipollino/resources/template/head.tex:\n",
      "\n",
      "./Chipollino/README.md:\n"
     ]
    }
   ],
   "source": [
    "# Functions.h functions\n",
    "rewrite_in_file(\n",
    "    file_path=data[\"chipollino_path\"] + \"/libs/FuncLib/include/FuncLib/Functions.h\",\n",
    "    insert_place=\"vector<Function> functions\",\n",
    "    new_text=generate_funcs_vector(),\n",
    ")\n",
    "# interpreter.cpp apply_function()\n",
    "add_to_interpreter_apply_function()\n",
    "# Typization.h\n",
    "add_to_typization()\n",
    "# templates\n",
    "generate_templates()\n",
    "# head.tex\n",
    "add_to_tex_head()\n",
    "# README.md\n",
    "add_to_readme()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9455ef6715782903d486227c510e51b80ce3c253b2853ac59d80d1f679697701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
